심사위원 예상 질문 및 한줄 답변
============================================================

Q1. 이 프로젝트를 시작하게 된 동기는 무엇인가요? 기존 회의록 솔루션의 어떤 문제점을 해결하려고 했나요?
A1. 기존 STT 솔루션은 화자 분리와 내용 검색이 부족했고, 우리는 STT+화자분리+자동요약+RAG챗봇을 통합한 End-to-End 회의록 관리 시스템을 만들었습니다.

Q2. 프로젝트의 핵심 기술은 무엇이고, 각각 어떤 역할을 하나요?
A2. 4가지 핵심 기술은 Gemini AI(STT+요약), RAG(벡터검색+정확한 출처), 이중 DB(SQLite+ChromaDB), 스마트 청킹(화자/시간/크기 고려)입니다.

Q3. 타겟 사용자는 누구이며, 어떤 사용 시나리오를 상정했나요?
A3. 기업 회의, 학술 세미나, 강의 녹음을 대상으로 실시간 회의록 작성, 과거 회의 검색, 팀 협업, 리마인더 시나리오를 상정했습니다.

Q4. 왜 웹 애플리케이션으로 개발했나요? 모바일 앱이나 데스크톱 앱 대신 선택한 이유는?
A4. 크로스 플랫폼 지원, 설치 불필요, 빠른 배포, 협업 용이성 때문에 Flask 기반 웹으로 개발했고 향후 PWA 전환을 고려하고 있습니다.

Q5. 이 프로젝트의 비즈니스 모델이나 실제 상용화 가능성은 어떻게 보시나요?
A5. Freemium(무료 월 10개, 유료 무제한)과 Enterprise(온프레미스) 모델로 한국어 특화+RAG 챗봇을 강점으로 상용화 가능하며, GCP 배포와 Firebase 인증이 완료되었습니다.

Q6. 왜 Flask를 선택했나요? Django나 FastAPI 대신 Flask를 선택한 이유는?
A6. 경량성, 빠른 프로토타이핑, 유연성, 낮은 학습 곡선으로 MVP 개발에 최적이었고, 트래픽 증가 시 FastAPI로 마이그레이션을 고려하고 있습니다.

Q7. 데이터베이스를 SQLite와 ChromaDB로 이원화한 이유는? 하나의 DB로 통합하지 않은 이유는?
A7. SQLite는 메타데이터와 관계 관리에, ChromaDB는 의미론적 검색에 특화되어 있어 각각의 강점을 활용하고 독립적 확장이 가능하도록 이원화했습니다.

Q8. 마이크로서비스 대신 모놀리식 아키텍처를 선택한 이유는?
A8. 소규모 팀(4명)에서 빠른 MVP 개발을 위해 모놀리식을 선택했고, 사용자 10,000명 돌파 시 STT와 RAG를 순차적으로 분리할 계획입니다.

Q9. 파일 업로드부터 회의록 생성까지의 전체 파이프라인을 설계할 때 가장 고민한 부분은?
A9. STT 실패 시 폴백 로직, 긴 처리 시간에 대한 SSE 진행률 표시, SQLite-ChromaDB 동기화, Gemini API 비용 최적화(Pro/Flash 구분)가 주요 고민이었습니다.

Q10. 시스템의 병목 지점은 어디이고, 어떻게 해결할 계획인가요?
A10. STT 처리(2-3분)가 가장 큰 병목으로 병렬 처리와 스트리밍 STT로 개선하고, 임베딩은 배치 처리로, 전체 검색은 메타데이터 필터 활용으로 최적화할 계획입니다.

Q11. Gemini를 선택한 이유는? OpenAI Whisper나 다른 STT 모델 대신 Gemini를 선택한 결정적 이유는?
A11. Gemini는 화자 분리가 내장되어 있고, 한국어 특화 학습으로 95% 정확도를 보이며, 멀티모달 지원과 적정 비용으로 Whisper 대비 개발 시간을 크게 단축했습니다.

Q12. Gemini Pro와 Flash를 구분해서 사용한 이유는?
A12. STT는 화자 분리 정확도가 중요해 Pro를 사용하고, 요약/마인드맵/챗봇은 속도가 중요해 Flash를 사용하여 품질을 유지하면서 60% 비용을 절감했습니다.

Q13. OpenAI text-embedding-3-small을 임베딩 모델로 선택한 이유는?
A13. 1536차원으로 충분한 검색 품질(95%)을 제공하면서 large 대비 2배 저렴하고, LangChain/ChromaDB와 완벽 호환되며 한국어를 우수하게 지원합니다.

Q14. RAG 시스템에서 Self-Query 대신 Similarity Search를 사용하는 이유는?
A14. 2025-11-08 Self-Query 시도 시 ChromaDB 호환성 문제와 필터 형식 오류가 빈번해 안정성과 디버깅 용이성을 위해 Similarity Search를 선택했습니다.

Q15. 스마트 청킹 알고리즘을 직접 구현한 이유는? LangChain의 RecursiveCharacterTextSplitter를 사용하지 않은 이유는?
A15. 회의록은 화자 변경과 시간 간격이 주제 전환과 높은 상관관계가 있어 이를 고려한 직접 구현으로 검색 품질과 출처 정확도를 100% 달성했습니다.

Q16. 왜 LLM을 사용한 청킹이 아닌 규칙 기반 청킹을 선택했나요?
A16. 규칙 기반은 밀리초 단위로 빠르고 무료이며 예측 가능하고, 화자 변경+시간 간격이 실제로 주제 전환과 높은 상관관계를 보여 충분한 품질을 제공합니다.

Q17. 할루시네이션 방지를 위해 어떤 전략을 사용했나요?
A17. 명시적 제약("반드시 검색된 내용 안에서만"), 솔직한 답변 유도("모르면 모른다고"), 외부 지식 금지, 메타데이터 우선 참조로 100개 테스트에서 0건 할루시네이션을 달성했습니다.

Q18. 앞으로 멀티모달 (비디오, 이미지) 지원 계획이 있나요?
A18. 1단계로 비디오에서 화면 캡처 분석, 2단계로 Gemini Vision을 활용한 화이트보드/차트 분석, 3단계로 텍스트+이미지 하이브리드 검색을 계획하고 있습니다.

Q19. 왜 PostgreSQL이나 MySQL 대신 SQLite를 선택했나요?
A19. 소규모 사용자에게 충분한 성능을 제공하고 배포가 단순하며 비용이 무료여서 SQLite를 선택했고, SQLAlchemy ORM 사용으로 사용자 1,000명 시 PostgreSQL 전환이 용이합니다.

Q20. meeting_dialogues 테이블에 confidence 필드를 추가한 이유는? 실제로 활용하고 있나요?
A20. STT 품질 모니터링과 향후 저신뢰도 필터링, 사용자 피드백을 위해 추가했으며, 현재는 저장만 하고 평균 0.92로 향후 품질 개선 시 핵심 지표로 활용할 예정입니다.

Q21. meeting_shares 테이블의 permission 필드 (read, write, admin)는 실제로 어떻게 구현되어 있나요?
A21. read는 조회+챗봇, write는 제목/노트 수정, admin은 삭제+재공유 권한이며 utils/user_manager.py에서 can_edit_meeting, can_delete_meeting 함수로 구현되어 있습니다.

Q22. ChromaDB의 메타데이터와 SQLite의 데이터가 불일치하면 어떻게 처리하나요?
A22. 현재는 순차 업데이트로 불일치 가능성이 있어 향후 2-Phase Commit과 주기적 정합성 검증 스크립트로 개선할 계획입니다.

Q23. 대용량 회의록 (100만 개)을 처리할 수 있나요? 확장성은?
A23. 현재 1,000개까지 최적, 10,000개에서 PostgreSQL+Redis 전환, 100,000개에서 Sharding, 1,000,000개에서 Elasticsearch+마이크로서비스 전환을 계획하고 있습니다.

Q24. RAG에서 chunks와 subtopics를 분리한 이유는? 하나의 컬렉션으로 통합하지 않은 이유는?
A24. chunks는 상세한 발언 내용을, subtopics는 주제별 요약을 제공하여 개요+상세를 함께 제공함으로써 챗봇 성공률 100%와 출처 다양성을 달성했습니다.

Q25. RAG에서 k=3씩 (총 6개)를 선택한 이유는? 더 많거나 적게 가져오면 안 되나요?
A25. 실험 결과 k=3에서 100% 정확도와 3.77초 응답 시간을 달성했고, k=5는 느리고 k=1은 맥락이 부족해 최적값으로 선택했습니다.

Q26. 전체 노트 검색에서 k=30으로 검색 후 Python 필터링하는 방식이 비효율적인데, 왜 이 방식을 선택했나요?
A26. ChromaDB 메타데이터 필터가 $in 연산자를 지원하지 않고 Self-Query 실패 경험으로 안정성을 우선했으며, ChromaDB 업데이트 시 즉시 개선할 계획입니다.

Q27. 챗봇이 답변할 때 출처(sources)를 항상 제공하는 이유는?
A27. 신뢰성 확보, 검증 가능성, 법적 근거 제공, UX 향상(타임스탬프로 이동), 할루시네이션 방지를 위해 출처를 항상 제공합니다.

Q28. 챗봇 프롬프트에서 "회의 제목과 날짜는 메타데이터 참조"라고 명시한 이유는?
A28. 회의 중 사람들이 잘못된 제목/날짜를 언급하는 경우가 있어 본문 대신 정확한 메타데이터를 참조하도록 명시해 100개 테스트에서 0건 오류를 달성했습니다.

Q29. RAG 시스템의 가장 큰 도전 과제는 무엇이었나요?
A29. 의미 단위 청킹으로 검색 품질 30% 향상, 4가지 프롬프트 전략으로 0% 할루시네이션 달성, Python 필터링으로 3.77초 응답 시간 달성이 주요 도전이었습니다.

Q30. 향후 RAG 시스템을 어떻게 개선할 계획인가요?
A30. 1단계 Reranking(10-20% 품질 향상), 2단계 Hybrid Search(고유명사 개선), 3단계 Query Expansion(recall 향상), 4단계 멀티홉 추론을 계획하고 있습니다.

Q31. 30분 회의를 처리하는 데 4분이 걸리는데, 이게 빠른 건가요?
A31. 경쟁사(Otter 5분, Fireflies 6분, Clova 3분) 대비 중간 수준이며 RAG 챗봇까지 포함하면 경쟁력 있고, 병렬 처리로 2분까지 단축 목표입니다.

Q32. 배치 임베딩을 사용한다고 했는데, 실제 성능 개선 효과는?
A32. 15개 청크 기준 하나씩(7.5초)에서 배치(0.8초)로 전환하여 90% 단축했고, API 호출 오버헤드 감소와 서버 내부 병렬 처리가 주효했습니다.

Q33. ChromaDB 대신 Pinecone이나 Weaviate 같은 상용 벡터 DB를 고려하지 않은 이유는?
A33. MVP 단계에서 비용 최소화(ChromaDB 무료 vs Pinecone $70/월)와 데이터 주권 확보를 위해 선택했고, 10만 벡터 초과 시 전환을 고려하고 있습니다.

Q34. 인덱스 최적화는 어떻게 했나요?
A34. meetings(owner_id, meeting_date), meeting_dialogues(meeting_id, start_time), meeting_shares(shared_with_user_id)에 6개 인덱스를 적용해 10~100배 성능을 향상시켰습니다.

Q35. 캐싱 전략은?
A35. 현재는 Flask 세션만 사용하고, 향후 Redis로 임베딩 캐싱, 검색 결과 캐싱(10분), 회의 정보 캐싱(30분)을 도입해 응답 시간 70% 단축을 목표로 합니다.

Q36. Firebase Auth를 선택한 이유는? 직접 구현하지 않은 이유는?
A36. 보안(자동 처리), Google OAuth(간편 로그인), 빠른 개발(1일 vs 자체 구현 2주), 무료 티어(10,000 MAU)로 리스크를 최소화하고 MVP를 빠르게 개발했습니다.

Q37. 세션 관리는 어떻게 하고 있나요? JWT 대신 세션을 선택한 이유는?
A37. JWT는 탈취 위험과 즉시 무효화 어려움이 있어 서버 사이드 세션을 선택했고, HTTPS only, HttpOnly, SameSite 설정으로 보안을 강화했습니다.

Q38. 공유 기능의 보안 취약점은 없나요? 누구나 링크만 있으면 접근 가능한가요?
A38. 링크 공유는 불가하고 이메일 기반 공유만 가능하며, 모든 API에서 3단계 권한 체크(소유자, 공유, 관리자)로 IDOR과 브루트 포스를 방지합니다.

Q39. 사용자 피드백이나 사용성 테스트를 진행했나요?
A39. 내부 테스트(20건)로 MP4 지원/SSE 추가, 외부 데모(10명)로 마인드맵 개선, 챗봇 테스트(100개)로 100% 성공률 달성 후 UI/UX를 개선했습니다.

Q40. 긴 회의 (2시간 이상)도 처리 가능한가요?
A40. 현재 500MB 제한으로 2시간까지 가능하나 15분 소요되어 향후 30분씩 분할하여 병렬 STT 처리로 5분까지 단축할 계획입니다.

Q41. 모바일에서도 사용 가능한가요?
A41. 반응형 디자인으로 회의록 조회와 챗봇은 완벽 지원하나 파일 업로드는 모바일 브라우저 제약이 있어 3개월 내 PWA 전환을 계획하고 있습니다.

Q42. 실시간 회의록 작성 기능 계획은?
A42. Phase 1 WebSocket 스트리밍 STT(3개월), Phase 2 실시간 화자 분리(6개월), Phase 3 점진적 요약(9개월)로 1년 내 베타 출시를 목표로 합니다.

Q43. 팀원들과 어떻게 협업했나요? 역할 분담은?
A43. 4명 팀으로 백엔드 2명(STT/AI/DB/RAG), 프론트엔드 1명(UI/UX/React/Auth), 풀스택 1명(Flask/GCP/배포)으로 나뉘어 GitHub PR 기반으로 주 2회 회의하며 협업했습니다.

Q44. 버전 관리 및 Git 전략은?
A44. Git Flow 간소화(main-develop-feature)로 브랜치 전략을 수립하고, 커밋 메시지 규칙(feat/fix/docs/refactor/test)과 최소 1명 승인 필요한 PR 규칙을 적용했습니다.

Q45. 코드 리뷰 과정은?
A45. 기능 정확성, 코드 품질, 성능, 보안, 테스트 5가지 체크리스트로 평균 30분간 리뷰하며, SQL Injection/XSS 방지와 권한 체크를 필수로 확인합니다.

Q46. 현재 시스템의 가장 큰 한계점은 무엇인가요?
A46. 처리 시간(4분→1분 목표), 비용(회의당 $0.20→$0.05 목표), 확장성(SQLite→PostgreSQL+Redis)이 3가지 주요 한계로 현재는 MVP 단계입니다.

Q47. 경쟁사 대비 약점은 무엇인가요?
A47. 실시간 처리 부재(1년 내 추가), Zoom/Teams 통합 부족(Zoom API 계획), 브랜드 인지도 낮음(한국 시장 집중)이 약점이나 RAG 챗봇과 한국어 특화가 강점입니다.

Q48. 만약 처음부터 다시 한다면 어떻게 하겠습니까?
A48. pytest+GitHub Actions로 테스트 자동화, FastAPI로 비동기 처리를 하되, 이중 DB와 Gemini+OpenAI 조합은 유지하고, Self-Query 시도와 조기 최적화는 피하겠습니다.

Q49. 향후 3개월, 6개월, 1년 로드맵은?
A49. 3개월: PWA+Reranking+Redis+PostgreSQL, 6개월: 실시간 회의록 베타+Zoom 플러그인+멀티모달, 1년: 유료 플랜+기업 고객 10개사+월활성 사용자 1,000명 목표입니다.

Q50. 마지막으로 이 프로젝트를 통해 배운 점은?
A50. AI 통합의 복잡성(프롬프트 엔지니어링, 할루시네이션 방지), 데이터베이스 역할 분담, 배치 처리의 위력, 사용자 중심 설계, 협업의 중요성, 완벽보다는 핵심 가치 제공과 점진적 개선이 중요함을 배웠습니다.
