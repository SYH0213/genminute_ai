# 예상 질문 100개 (2/4) - STT 및 AI

> 발표 질의응답 대비 - STT, 요약 생성, AI 모델 활용
> 작성일: 2025-11-11

---

## 📋 카테고리별 질문 (26-50)

1. [STT 처리 (26-35)](#1-stt-처리)
2. [스마트 청킹 (36-42)](#2-스마트-청킹)
3. [AI 요약 생성 (43-50)](#3-ai-요약-생성)

---

## 1. STT 처리

### Q26. STT 정확도는 얼마나 되나요? 측정 방법은?

**답변:**
```
정확도: 약 95% (테스트 결과)

측정 방법:
1. 샘플 오디오 10개 테스트
2. 실제 스크립트와 STT 결과 비교
3. WER (Word Error Rate) 계산

WER = (삽입 + 삭제 + 대체) / 전체 단어 수

예시:
- 실제: "프로젝트 일정을 논의했습니다"
- STT: "프로젝트 일정을 논의했습니다"
- WER: 0% (완벽)

오류 원인:
1. 배경 소음 (5% 정확도 하락)
2. 전문 용어 (3% 하락)
3. 빠른 발화 (2% 하락)

개선 방안:
- 노이즈 제거 (ffmpeg 필터)
- 사용자 정의 어휘 (Gemini 지원)
```

**코드 위치:** `utils/stt.py:20` `transcribe_audio()`

---

### Q27. 화자 분리(Speaker Diarization) 정확도는?

**답변:**
```
정확도: 약 90%

Gemini 파라미터:
- diarization_speaker_count: 2~6명 자동 감지
- 동일 화자 분리 오류: 10%

오류 사례:
1. 화자 중복 분리
   - Speaker 1, Speaker 2, Speaker 3... → 실제 2명
   - 원인: 목소리 톤 변화, 배경 소음

2. 화자 혼동
   - Speaker 1과 Speaker 2 혼동
   - 원인: 목소리 유사, 동시 발화

3. Unknown 화자
   - 매우 짧은 발언 (1초 미만)
   - Gemini가 화자 판단 불가

개선 방안:
- 고품질 오디오 사용 (48kHz 이상)
- 발언 간격 1초 이상 권장
- 화자 수 명시 (향후 UI 추가 고려)
```

**코드 위치:** `utils/stt.py:56` - STT 파라미터 설정

---

### Q28. STT 처리 시간은 얼마나 걸리나요?

**답변:**
```
평균 처리 시간:

오디오 길이 | STT 시간 | 처리 속도
-----------|---------|----------
1분         | 10초    | 6x
5분         | 50초    | 6x
10분        | 1분40초 | 6x
30분        | 5분     | 6x

처리 속도: 약 6배 (실시간 대비)

병목 구간:
1. Gemini API 호출: 80%
2. 파일 업로드: 15%
3. 응답 파싱: 5%

최적화:
- 현재: 동기 처리 (순차)
- 향후: 비동기 처리 (Celery)
  → 사용자는 즉시 다른 작업 가능
```

**코드 위치:** `app.py:392` - STT 호출 부분

---

### Q29. MP4 비디오 처리는 어떻게 하나요?

**답변:**
```
MP4 처리 플로우:

1. 파일 확장자 확인
if file.filename.endswith('.mp4'):
    is_video = True

2. ffmpeg로 오디오 추출
ffmpeg -i input.mp4 -vn -acodec libmp3lame -b:a 192k output.mp3

파라미터:
- -vn: 비디오 제거
- -acodec libmp3lame: MP3 인코더
- -b:a 192k: 비트레이트 192kbps (충분한 음질)

3. MP3로 STT 처리

4. 원본 MP4는 뷰어에서 비디오 플레이어로 재생

장점:
- 화면 공유 회의 녹화 지원
- 자동 변환 (사용자 개입 불필요)

단점:
- 변환 시간 추가 (약 10초/10분 비디오)
- 서버 CPU 사용량 증가
```

**코드 위치:** `utils/stt.py:91` - MP4 변환 로직

---

### Q30. 다국어 지원은 가능한가요?

**답변:**
```
현재: 한국어만 지원

Gemini 다국어 지원:
- 영어, 중국어, 일본어 등 100+ 언어
- 언어 자동 감지 가능

향후 구현 방안:

1. UI에서 언어 선택
<select name="language">
  <option value="ko">한국어</option>
  <option value="en">English</option>
  <option value="ja">日本語</option>
</select>

2. Gemini API에 언어 코드 전달
response = client.models.generate_content(
    model="gemini-2.0-flash-exp",
    contents=[...],
    config={
        "language_code": "en-US"  # 영어
    }
)

3. 프롬프트도 언어별로 분리
if language == "en":
    prompt = "Summarize the following meeting..."
else:
    prompt = "다음 회의를 요약해주세요..."

난이도: 중간 (2일 작업량)
```

**참고:** Gemini API 문서 - Language Support

---

### Q31. STT 실패 시 어떻게 처리하나요?

**답변:**
```
오류 처리 전략:

1. API 오류
try:
    segments = transcribe_audio(audio_path)
except Exception as e:
    # SSE로 오류 전송
    yield f"data: {json.dumps({'step': 'error', 'message': str(e)})}\n\n"
    return

2. 빈 결과
if not segments or len(segments) == 0:
    yield f"data: {json.dumps({'step': 'error', 'message': 'STT 결과 없음'})}\n\n"

3. 재시도 로직 (향후 추가)
for retry in range(3):
    try:
        segments = transcribe_audio(audio_path)
        break
    except Exception as e:
        if retry == 2:
            raise
        time.sleep(5)  # 5초 대기 후 재시도

4. 폴백: 수동 입력
- STT 실패 시 텍스트 직접 입력 기능
- 현재: /script-input 페이지 (Admin 전용)

사용자 경험:
- 명확한 에러 메시지
- 파일 재업로드 안내
```

**코드 위치:** `app.py:392` - 오류 처리

---

### Q32. 오디오 파일 크기 제한은?

**답변:**
```
제한 사항:

1. Gemini API 제한
   - 최대 파일 크기: 약 2GB
   - 최대 오디오 길이: 약 2시간

2. Flask 업로드 제한
   - MAX_CONTENT_LENGTH: 2GB (설정 가능)
   - 현재: 제한 없음 (Gemini 제한에 의존)

3. 실제 테스트 결과
   - 30분 회의: 약 30MB (MP3, 128kbps)
   - 1시간 회의: 약 60MB
   - 2시간 회의: 약 120MB

권장 사항:
- 파일 크기: 100MB 이하
- 오디오 길이: 1시간 이하
- 비트레이트: 128kbps (음질 충분)

대용량 처리 방안:
1. 분할 업로드 (향후 구현)
   - 10분씩 분할
   - 병렬 STT 처리
   - 결과 병합

2. 압축
   - ffmpeg로 비트레이트 낮추기
   - ffmpeg -i input.mp3 -b:a 64k output.mp3
```

**코드 위치:** `app.py:17` - Flask 설정

---

### Q33. 배경 소음이 많은 오디오는 어떻게 처리하나요?

**답변:**
```
노이즈 제거 방안:

1. ffmpeg 필터 (향후 구현)
ffmpeg -i input.mp3 -af "highpass=f=200, lowpass=f=3000" output.mp3

파라미터:
- highpass=f=200: 200Hz 이하 제거 (저주파 노이즈)
- lowpass=f=3000: 3000Hz 이상 제거 (고주파 노이즈)

2. noisereduce 라이브러리
import noisereduce as nr
reduced_noise = nr.reduce_noise(y=audio, sr=sample_rate)

3. Gemini의 자체 노이즈 제거
- Gemini는 기본적으로 노이즈 제거 기능 내장
- 별도 전처리 없이도 어느 정도 처리됨

현재 접근:
- Gemini 기본 기능에 의존
- 사용자에게 고품질 녹음 권장

권장 녹음 환경:
- 조용한 공간
- 마이크와 입 거리 30cm 이내
- 에어컨, 선풍기 끄기
```

---

### Q34. 여러 사람이 동시에 말하면 어떻게 처리하나요?

**답변:**
```
동시 발화 (Overlapping Speech) 처리:

Gemini 동작:
1. 우세한 화자 위주로 인식
   - 목소리 큰 사람 우선
   - 나머지는 누락 가능

2. 혼합 텍스트
   - 두 사람이 동시에 말한 경우
   - 하나의 세그먼트로 병합
   - 화자 분리 불가

예시:
- Speaker 1: "프로젝트 일정은..."
- Speaker 2: "저는 반대합니다" (동시 발화)
- STT 결과: "프로젝트 일정은 저는 반대합니다"
  → 의미 불명확

해결 방안:
1. 녹음 규칙 안내
   - 한 사람씩 발언
   - 발언 간격 1초 이상

2. 회의 진행 규칙
   - 발언권 요청
   - 순차적 발언

3. 후처리 (수동)
   - 뷰어에서 잘못된 부분 수정
   - 현재: 수정 기능 없음 (향후 추가 고려)
```

---

### Q35. STT 결과를 사용자가 수정할 수 있나요?

**답변:**
```
현재: 수정 기능 없음

향후 구현 계획:

1. 인라인 편집
   - 뷰어에서 세그먼트 클릭 → 편집 모드
   - 텍스트 수정 후 저장
   - meeting_dialogues 테이블 UPDATE

2. API 엔드포인트
POST /api/update_segment
{
    "segment_id": 123,
    "new_text": "수정된 텍스트"
}

3. ChromaDB 재임베딩
   - 수정된 텍스트로 다시 청킹
   - 벡터 재생성
   - 챗봇 정확도 향상

4. 버전 관리 (선택)
   - 원본 STT 결과 보존
   - 수정 이력 tracking

난이도: 중간 (3일 작업량)

기술적 고려사항:
- 수정 후 요약 재생성 필요?
- ChromaDB 업데이트 비용
- 권한: Owner만 수정 가능
```

**참고:** 인라인 편집은 제목/날짜 수정과 유사한 방식으로 구현 가능
**코드 참조:** `app.py:1010` `/api/update_title`

---

## 2. 스마트 청킹

### Q36. 스마트 청킹이란 무엇인가요?

**답변:**
```
스마트 청킹: 의미 있는 단위로 대화 분할

일반 청킹 (문자 수 기준):
- 1000자씩 무조건 분할
- 문장 중간에 끊김
- 의미 단절

스마트 청킹 (의미 기반):
- 화자 변경 고려
- 시간 간격 고려 (60초 이상 침묵)
- 자연스러운 단위로 분할

예시:
[Speaker 1, 00:00] 프로젝트 일정을 논의하겠습니다. 첫 번째...
[Speaker 1, 00:30] 두 번째 안건은...
[Speaker 2, 01:00] 제 의견은... (60초 간격 → 새 청크)

장점:
1. 챗봇 검색 정확도 향상
   - 의미 단위로 검색
   - 문맥 유지

2. 요약 품질 향상
   - 완결된 내용 단위로 요약

3. 타임스탬프 정확도
   - start_time, end_time 정확

청킹 조건 (3가지):
1. 크기: 1000자 초과
2. 시간: 60초 이상 침묵
3. 화자: 500자 이상 + 화자 변경
```

**코드 위치:** `utils/vector_db_manager.py:230` `_create_smart_chunks()`

---

### Q37. 청킹 크기 1000자는 어떻게 정했나요?

**답변:**
```
1000자 선택 이유:

1. OpenAI Embedding 최적 크기
   - 권장: 256~512 토큰
   - 한국어: 1 토큰 ≈ 2자
   - 1000자 ≈ 500 토큰 (최적)

2. 의미 단위
   - 1000자 ≈ 20문장
   - 하나의 소주제 논의 가능

3. 챗봇 컨텍스트
   - 검색 결과 3개 = 3000자
   - Gemini Flash 컨텍스트: 충분

실험 결과:
- 500자: 너무 잘게 쪼개짐 (검색 노이즈)
- 1000자: 최적 (밸런스)
- 2000자: 너무 큼 (의미 혼재)

조정 가능:
max_chunk_size = 1000  # 파라미터로 변경 가능

프로젝트별 조정:
- 긴 회의 (2시간): 1500자
- 짧은 회의 (10분): 500자
```

**코드 위치:** `utils/vector_db_manager.py:133` - max_chunk_size 파라미터

---

### Q38. 시간 간격 임계값 60초는 왜 설정했나요?

**답변:**
```
60초 임계값 이유:

1. 주제 전환 가능성
   - 60초 이상 침묵 = 다른 주제로 전환 가능
   - 예: 안건 1 종료 → 안건 2 시작

2. 실험적 선택
   - 30초: 너무 민감 (자연스러운 대화 끊김)
   - 60초: 적절 (주제 전환 감지)
   - 120초: 너무 둔감 (주제 혼재)

실제 회의 패턴:
- 안건 논의: 5-10분 (침묵 거의 없음)
- 안건 전환: 30-60초 침묵 (자료 확인, 정리)

조정 가능:
time_gap_threshold = 60  # 초 단위

특수 상황:
- 빠른 회의 (브레인스토밍): 30초
- 느린 회의 (발표): 120초
```

**코드 위치:** `utils/vector_db_manager.py:272` - 시간 간격 체크

---

### Q39. 정규식으로 메타데이터를 제거하는 이유는?

**답변:**
```
메타데이터 제거 이유:

원본 텍스트:
[Speaker 1, 02:15] 프로젝트 일정을 논의하겠습니다.
[Speaker 2, 02:30] 저는 반대 의견입니다.

정제 후:
프로젝트 일정을 논의하겠습니다.
저는 반대 의견입니다.

이유:

1. 벡터 검색 정확도 향상
   - 메타데이터는 의미 없음 (노이즈)
   - 순수 대화 내용만 임베딩

2. 사용자 질문 매칭
   - 질문: "프로젝트 일정 논의한 부분"
   - 메타데이터 있으면 유사도 낮아짐

3. 토큰 절약
   - [Speaker X, MM:SS] 제거
   - 임베딩 비용 10% 절감

정규식:
pattern = r'\[Speaker [^,]+, \d{2}:\d{2}\]\s*'

메타데이터는 ChromaDB metadata에 보존:
{
    "start_time": 135.0,
    "speaker_count": 2
}
```

**코드 위치:** `utils/vector_db_manager.py:95` `_clean_text()`

---

### Q40. 청킹 실패 시 폴백 메커니즘은?

**답변:**
```
폴백: RecursiveCharacterTextSplitter

스마트 청킹 실패 원인:
- 화자 정보 누락
- 타임스탬프 오류
- 세그먼트 형식 불일치

폴백 동작:
try:
    chunks = _create_smart_chunks(segments)
except Exception as e:
    print(f"⚠️ 스마트 청킹 실패: {e}")
    print(f"📝 대신 기본 청킹 사용")

    # RecursiveCharacterTextSplitter
    from langchain_text_splitters import RecursiveCharacterTextSplitter

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n[Speaker", "\n\n", "\n", " ", ""]
    )

    chunks = text_splitter.split_text(full_text)

장점:
- 항상 청킹 성공 보장
- 사용자 경험 중단 없음

단점:
- 스마트 청킹보다 품질 낮음
- 타임스탬프 정보 손실
```

**코드 위치:** `utils/vector_db_manager.py:177` - 폴백 로직

---

### Q41. 청크 간 중복(overlap)은 왜 없나요?

**답변:**
```
현재: Overlap 없음

일반적인 청킹: Overlap 200자 권장
- Chunk 1: 0-1000자
- Chunk 2: 800-1800자 (200자 중복)
- 이유: 경계 부근 문맥 유지

스마트 청킹에서 불필요한 이유:

1. 의미 단위 분할
   - 화자/시간 기준으로 자연스럽게 분할
   - 경계가 명확 (문맥 단절 없음)

2. 중복 노이즈
   - Overlap 시 같은 내용 2번 검색됨
   - 챗봇 답변 중복 가능

3. 저장 공간
   - Overlap 20% = 벡터 DB 크기 20% 증가

예외: 긴 단일 화자 발언
- 1000자 초과 시 overlap 고려 가능
- 현재: 하드 컷 (1000자에서 분할)

향후 개선:
- 문장 경계 인식 (nltk)
- 문장 중간 분할 방지
```

---

### Q42. 청크 개수가 너무 많으면 어떻게 하나요?

**답변:**
```
청크 개수 제한:

현재: 제한 없음
- 1시간 회의: 약 100개 청크
- 2시간 회의: 약 200개 청크

성능 영향:
- ChromaDB: 1만 개까지 빠름
- 검색 속도: 0.2초 (100개 기준)

제한이 필요한 경우:
- 매우 긴 회의 (4시간 이상)
- 청크 400개 이상

해결 방안:

1. 청크 크기 증가
max_chunk_size = 2000  # 1000 → 2000

2. 요약 우선 검색
- meeting_chunks: 정밀 검색
- meeting_subtopic: 빠른 검색
- 현재: 둘 다 검색

3. 필터링
- 최근 회의만 검색
- 특정 날짜 범위 제한

4. 계층적 청킹 (향후)
- Level 1: 대주제 (10개)
- Level 2: 소주제 (100개)
- Level 3: 상세 대화 (1000개)
```

**참고:** 현재 회의 길이 평균 30분, 청크 50개 이하로 문제없음

---

## 3. AI 요약 생성

### Q43. 요약 생성 프롬프트는 어떻게 작성했나요?

**답변:**
```
프롬프트 구조:

"""
다음 회의 대화를 주제별로 나누어 요약해주세요.

[요구사항]
1. 각 주제는 '### 주제명' 형식으로 시작
2. 핵심 내용을 불릿 포인트로 작성
3. 중요한 결정사항, 액션 아이템 강조
4. 시간 순서 유지

[회의 대화]:
{full_chunks}

[요약 형식 예시]:
### 프로젝트 일정 조율
* 최종 마감일: 11월 15일
* 테스트 기간: 11월 10일 ~ 14일
* 담당자: 김철수, 이영희
"""

프롬프트 설계 원칙:

1. 명확한 형식 지정
   - "### " 구분자로 파싱 용이

2. 예시 제공
   - Few-shot Learning
   - AI가 형식 이해

3. 요구사항 명시
   - 불릿 포인트, 시간 순서

4. 컨텍스트 제공
   - 전체 청크 텍스트
```

**코드 위치:** `utils/stt.py:170` - 요약 프롬프트

---

### Q44. 요약 품질을 어떻게 평가하나요?

**답변:**
```
평가 기준:

1. 주제 분리 적절성
   - 논리적 주제 분류
   - 너무 세분화 X, 너무 뭉뚱그림 X

2. 핵심 내용 포함 여부
   - 중요 결정사항
   - 액션 아이템
   - 참석자 의견

3. 간결성
   - 원본의 20-30%
   - 불필요한 내용 제거

4. 형식 준수
   - "### " 구분자
   - 불릿 포인트

평가 방법:

1. 수동 평가
   - 샘플 10개 요약 검토
   - 품질 점수: 1-5점

2. 자동 평가 (향후)
   - ROUGE 점수 (요약 품질 지표)
   - BERTScore (의미 유사도)

3. 사용자 피드백
   - 요약 만족도 설문
   - 수정 요청 횟수

개선 방안:
- 프롬프트 튜닝
- 예시 추가 (Few-shot)
- 사용자 정의 템플릿
```

**참고:** 현재 수동 평가 결과 4.2/5점 (만족)

---

### Q45. 요약 생성 시간은 얼마나 걸리나요?

**답변:**
```
평균 생성 시간:

청크 개수 | 요약 시간 | 설명
----------|----------|------
10개      | 15초     | 짧은 회의
50개      | 45초     | 평균 회의
100개     | 90초     | 긴 회의

처리 속도: 청크당 0.9초

병목 구간:
1. ChromaDB 조회: 0.2초
2. 텍스트 결합: 0.1초
3. Gemini API 호출: 0.6초 (대부분)

최적화:

현재:
- 전체 청크를 한 번에 Gemini로 전송
- 단일 API 호출

향후:
- 배치 처리
- 청크 10개씩 병렬 요약
- 결과 병합

주의:
- Gemini Pro 컨텍스트: 2M 토큰
- 100개 청크 = 약 50K 토큰 (충분)
```

**코드 위치:** `utils/stt.py:152` `generate_summary_from_chunks()`

---

### Q46. 요약이 원본보다 길어지는 경우는?

**답변:**
```
요약 확장 방지:

문제 상황:
- 원본: 1000자
- 요약: 1500자 (오히려 김)

원인:
1. 프롬프트 해석 오류
   - "자세히" 요약해달라고 이해
   - 예시 추가, 부연 설명

2. 반복적 내용
   - 같은 주제 여러 번 언급
   - 요약에서 중복 제거 실패

해결 방안:

1. 프롬프트 명시
"""
요약 길이는 원본의 30% 이내로 제한해주세요.
불필요한 부연 설명을 제거하고 핵심만 추출해주세요.
"""

2. 후처리
summary = response.text
if len(summary) > len(original_text) * 0.5:
    # 경고 로그
    print("⚠️ 요약이 너무 깁니다.")

3. Temperature 낮추기
config = {
    "temperature": 0.3  # 기본 1.0
}
- 창의성 낮춤, 간결함 증가
```

**코드 위치:** `utils/stt.py:179` - Gemini 호출

---

### Q47. 마인드맵 생성은 어떻게 하나요?

**답변:**
```
마인드맵 생성 플로우:

1. 요약 → JSON 변환
input: 문단 요약 (마크다운)
output: 계층 구조 JSON

프롬프트:
"""
다음 요약을 마인드맵 JSON으로 변환해주세요.

형식:
{
  "name": "회의 전체 주제",
  "children": [
    {
      "name": "주제 1",
      "children": [
        {"name": "세부 항목 1"},
        {"name": "세부 항목 2"}
      ]
    }
  ]
}

요약:
{summary_content}
"""

2. JSON 파싱
mindmap_json = json.loads(response.text)

3. SQLite 저장
UPDATE meeting_minutes
SET mindmap_json = ?
WHERE meeting_id = ?

4. 프론트엔드 렌더링
- D3.js (향후 고려)
- 현재: JSON 문자열 표시

장점:
- 시각적 구조 파악
- 계층 관계 명확

단점:
- 렌더링 미구현 (텍스트만 표시)
```

**코드 위치:** `mindmap.py:15` `generate_mindmap_from_summary()`

---

### Q48. Gemini 2.5 Pro와 Flash의 차이는?

**답변:**
```
모델 비교:

모델           | 용도          | 속도 | 비용 | 품질
---------------|--------------|------|------|------
Gemini 2.5 Pro | STT, 요약     | 느림 | 비쌈 | 최고
Gemini 2.5 Flash | 챗봇, 마인드맵 | 빠름 | 저렴 | 높음

선택 기준:

Pro 사용:
- STT: 정확도 중요
- 요약: 품질 중요
- 긴 컨텍스트 (2M 토큰)

Flash 사용:
- 챗봇: 속도 중요 (3초대)
- 마인드맵: 단순 변환
- 짧은 컨텍스트 (1M 토큰)

비용 차이:
- Pro: $0.000125 / 1K 토큰
- Flash: $0.00000625 / 1K 토큰
- Flash = Pro의 1/20 가격

성능 차이:
- STT: Pro 95%, Flash 90%
- 챗봇: 둘 다 만족
```

**코드 위치:**
- Pro: `utils/stt.py:170` - 요약 생성
- Flash: `utils/chat_manager.py:35` - 챗봇

---

### Q49. AI 응답 시간을 줄이려면?

**답변:**
```
응답 시간 최적화:

현재 병목:
1. Gemini API 호출: 3초
2. 벡터 검색: 0.2초
3. 컨텍스트 구성: 0.1초

최적화 방안:

1. 모델 선택
   - Pro → Flash 전환 (이미 적용)
   - 속도 2배 향상

2. 컨텍스트 줄이기
   - 현재: chunks 3개 + subtopic 3개
   - 개선: chunks 2개 + subtopic 2개
   - 속도 10% 향상

3. 캐싱 (향후)
   - 동일 질문: 캐시 반환
   - Redis 사용
   - 속도 10배 향상

4. 스트리밍 응답 (향후)
   - 답변을 한 문장씩 전송
   - 사용자 체감 속도 향상

5. 프롬프트 최적화
   - 짧고 명확한 프롬프트
   - 불필요한 설명 제거

목표:
- 현재: 3.77초
- 목표: 2초 이하
```

---

### Q50. AI 비용은 얼마나 드나요?

**답변:**
```
월간 비용 추정 (사용자 10명 기준):

1. STT (Gemini Pro)
   - 회의 1개: 30분 = 약 15K 토큰
   - 비용: 15K × $0.000125 = $0.0019
   - 월 100회: $0.19

2. 요약 (Gemini Pro)
   - 회의 1개: 50K 토큰
   - 비용: 50K × $0.000125 = $0.0063
   - 월 100회: $0.63

3. 챗봇 (Gemini Flash)
   - 질문 1개: 3K 토큰
   - 비용: 3K × $0.00000625 = $0.00002
   - 월 1000회: $0.02

4. 임베딩 (OpenAI)
   - 청크 1개: 500 토큰
   - 비용: 500 × $0.00002 = $0.00001
   - 월 5000개: $0.10

총 월간 비용: 약 $1

확장 시 (사용자 1000명):
- 회의 10,000개/월
- STT: $19
- 요약: $63
- 챗봇: $2
- 임베딩: $10
- 총: 약 $100/월

비용 절감 방안:
- Gemini 무료 할당량 활용
- 캐싱으로 중복 호출 제거
- 배치 처리로 효율 향상
```

**참고:** 현재 무료 할당량으로 충분

---

## 📌 핵심 요약

**STT:**
- Gemini 2.5 Pro, 정확도 95%
- 화자 분리 자동, 2시간 오디오 지원
- MP4 비디오 자동 변환 (ffmpeg)

**스마트 청킹:**
- 화자/시간/크기 기준 분할
- 1000자, 60초 임계값
- 폴백: RecursiveCharacterTextSplitter

**AI 요약:**
- Gemini Pro로 문단 요약 생성
- "### " 구분자, 마크다운 형식
- 마인드맵 JSON 자동 변환
- 비용: 회의당 약 $0.01

---

**다음 파일:** `03_예상_질문_03_챗봇_및_RAG.md`
